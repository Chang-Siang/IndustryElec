{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "from plotly import tools\n",
    "from plotly.offline import iplot\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "from pandas.core.frame import DataFrame\n",
    "from matplotlib.font_manager import FontProperties \n",
    "import matplotlib\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import datetime\n",
    "import numpy as geek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 7\n",
    "\n",
    "#上週三到本週二\n",
    "trainDateStart = '2017-01-04'\n",
    "trainDateEnd = '2019-01-01'\n",
    "\n",
    "preDateStart = '2019-01-02'\n",
    "preDateEnd = '2019-09-24'\n",
    "\n",
    "predictPeakLoad = pd.read_csv('predictPeakLoad_週三到週二_1106_MAPE_2_278(訓練資料2017_2018).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/elec_merge_20160101_20190930.csv')\n",
    "#將日期欄位轉為 datetime 格式。\n",
    "df['日期'] = pd.to_datetime(df['日期'], format='%Y-%m-%d')\n",
    "\n",
    "#選擇要使用的欄位\n",
    "selected_features = ['工業用電(百萬度)', 'isHoliday_shift', 'dayOfYear', 'weekUpdate_shift', 'Temp_Taipei_shift', '尖峰負載(MW)']\n",
    "\n",
    "#補星期幾\n",
    "#2016年01月01日 -> 星期五 ， 2016年01月02日 -> 星期六\n",
    "#2019年09月29日 -> 星期日 ， 2019年09月30日 -> 星期一\n",
    "df['week'] = np.nan\n",
    "week = [7, 1, 2, 3, 4, 5, 6]\n",
    "while len(week)<(len(df['week'])-4):\n",
    "     week = np.concatenate((week, [7, 1, 2, 3, 4, 5, 6]), axis = None)\n",
    "week = np.concatenate([[5,6], week, [7,1]])\n",
    "\n",
    "df['week'] = week\n",
    "df['week_update'] = week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2016年\n",
    "week_column = 'week_update'\n",
    "df.at[df['日期']=='2016-01-01', week_column]= 7\n",
    "df.at[df['日期']=='2016-01-30', week_column]= 5\n",
    "\n",
    "df.at[df['日期']=='2016-02-07', week_column]= 7\n",
    "df.at[df['日期']=='2016-02-08', week_column]= 7\n",
    "df.at[df['日期']=='2016-02-09', week_column]= 7\n",
    "df.at[df['日期']=='2016-02-10', week_column]= 7\n",
    "df.at[df['日期']=='2016-02-11', week_column]= 7\n",
    "df.at[df['日期']=='2016-02-12', week_column]= 7\n",
    "\n",
    "df.at[df['日期']=='2016-02-28', week_column]= 7 #不變\n",
    "df.at[df['日期']=='2016-02-29', week_column]= 7\n",
    "df.at[df['日期']=='2016-03-01', week_column]= 1\n",
    "\n",
    "\n",
    "df.at[df['日期']=='2016-04-04', week_column]= 7\n",
    "df.at[df['日期']=='2016-04-05', week_column]= 1\n",
    "df.at[df['日期']=='2016-04-06', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2016-05-01', week_column]= 7 #不變\n",
    "\n",
    "df.at[df['日期']=='2016-06-04', week_column]= 5\n",
    "\n",
    "df.at[df['日期']=='2016-06-08', week_column]= 5\n",
    "df.at[df['日期']=='2016-06-09', week_column]= 7\n",
    "df.at[df['日期']=='2016-06-10', week_column]= 7\n",
    "\n",
    "df.at[df['日期']=='2016-09-10', week_column]= 5\n",
    "\n",
    "df.at[df['日期']=='2016-09-14', week_column]= 5\n",
    "df.at[df['日期']=='2016-09-15', week_column]= 7\n",
    "df.at[df['日期']=='2016-09-16', week_column]= 7\n",
    "\n",
    "df.at[df['日期']=='2016-10-10', week_column]= 6\n",
    "df.at[df['日期']=='2016-10-11', week_column]= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017年\n",
    "week_column = 'week_update'\n",
    "df.at[df['日期']=='2017-01-02', week_column]= 7\n",
    "df.at[df['日期']=='2017-01-03', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2017-01-26', week_column]= 5\n",
    "df.at[df['日期']=='2017-01-27', week_column]= 7\n",
    "df.at[df['日期']=='2017-01-28', week_column]= 7\n",
    "df.at[df['日期']=='2017-01-29', week_column]= 7\n",
    "df.at[df['日期']=='2017-01-30', week_column]= 7\n",
    "df.at[df['日期']=='2017-01-31', week_column]= 7\n",
    "df.at[df['日期']=='2017-02-01', week_column]= 7\n",
    "df.at[df['日期']=='2017-02-02', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2017-02-18', week_column]= 5\n",
    "\n",
    "df.at[df['日期']=='2017-02-27', week_column]= 7\n",
    "df.at[df['日期']=='2017-02-28', week_column]= 6\n",
    "df.at[df['日期']=='2017-03-01', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2017-04-03', week_column]= 7\n",
    "df.at[df['日期']=='2017-04-04', week_column]= 6\n",
    "df.at[df['日期']=='2017-04-05', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2017-05-01', week_column]= 6\n",
    "df.at[df['日期']=='2017-05-02', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2017-05-29', week_column]= 7\n",
    "df.at[df['日期']=='2017-05-30', week_column]= 6\n",
    "df.at[df['日期']=='2017-05-31', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2017-06-03', week_column]= 5\n",
    "df.at[df['日期']=='2017-09-30', week_column]= 5\n",
    "\n",
    "df.at[df['日期']=='2017-10-03', week_column]= 5\n",
    "df.at[df['日期']=='2017-10-04', week_column]= 7\n",
    "df.at[df['日期']=='2017-10-05', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2017-10-09', week_column]= 7\n",
    "df.at[df['日期']=='2017-10-10', week_column]= 6\n",
    "df.at[df['日期']=='2017-10-11', week_column]= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018年\n",
    "week_column = 'week_update'\n",
    "df.at[df['日期']=='2018-01-01', week_column]= 7\n",
    "df.at[df['日期']=='2018-01-02', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2018-02-14', week_column]= 5\n",
    "df.at[df['日期']=='2018-02-15', week_column]= 7\n",
    "df.at[df['日期']=='2018-02-16', week_column]= 7\n",
    "df.at[df['日期']=='2018-02-17', week_column]= 7\n",
    "df.at[df['日期']=='2018-02-18', week_column]= 7\n",
    "df.at[df['日期']=='2018-02-19', week_column]= 7\n",
    "df.at[df['日期']=='2018-02-20', week_column]= 7\n",
    "df.at[df['日期']=='2018-02-21', week_column]= 1\n",
    "\n",
    "\n",
    "df.at[df['日期']=='2018-02-27', week_column]= 5\n",
    "df.at[df['日期']=='2018-02-28', week_column]= 7\n",
    "df.at[df['日期']=='2018-03-01', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2018-03-31', week_column]= 5\n",
    "\n",
    "df.at[df['日期']=='2018-04-04', week_column]= 6\n",
    "df.at[df['日期']=='2018-04-05', week_column]= 7\n",
    "df.at[df['日期']=='2018-04-06', week_column]= 7\n",
    "df.at[df['日期']=='2018-04-07', week_column]= 7\n",
    "\n",
    "df.at[df['日期']=='2018-04-30', week_column]= 5\n",
    "df.at[df['日期']=='2018-05-01', week_column]= 6\n",
    "df.at[df['日期']=='2018-05-02', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2018-06-18', week_column]= 7\n",
    "df.at[df['日期']=='2018-06-19', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2018-09-24', week_column]= 7\n",
    "df.at[df['日期']=='2018-09-25', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2018-10-09', week_column]= 5\n",
    "df.at[df['日期']=='2018-10-10', week_column]= 6\n",
    "df.at[df['日期']=='2018-10-11', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2018-12-22', week_column]= 5\n",
    "df.at[df['日期']=='2018-12-31', week_column]= 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019年\n",
    "week_column = 'week_update'\n",
    "df.at[df['日期']=='2019-01-01', week_column]= 7\n",
    "df.at[df['日期']=='2019-01-02', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2019-01-19', week_column]= 5\n",
    "\n",
    "df.at[df['日期']=='2019-02-04', week_column]= 7\n",
    "df.at[df['日期']=='2019-02-05', week_column]= 7\n",
    "df.at[df['日期']=='2019-02-06', week_column]= 7\n",
    "df.at[df['日期']=='2019-02-07', week_column]= 7\n",
    "df.at[df['日期']=='2019-02-08', week_column]= 7\n",
    "# df.at[df['日期']=='2019-02-09', week_column]= 7\n",
    "\n",
    "df.at[df['日期']=='2019-02-23', week_column]= 5\n",
    "\n",
    "df.at[df['日期']=='2019-02-27', week_column]= 5\n",
    "df.at[df['日期']=='2019-02-28', week_column]= 7\n",
    "df.at[df['日期']=='2019-03-01', week_column]= 7\n",
    "# df.at[df['日期']=='2019-03-02', week_column]= 7\n",
    "\n",
    "df.at[df['日期']=='2019-04-03', week_column]= 5\n",
    "df.at[df['日期']=='2019-04-04', week_column]= 7\n",
    "df.at[df['日期']=='2019-04-05', week_column]= 7\n",
    "# df.at[df['日期']=='2019-04-06', week_column]= 7\n",
    "\n",
    "df.at[df['日期']=='2019-04-30', week_column]= 5\n",
    "df.at[df['日期']=='2019-05-01', week_column]= 6\n",
    "df.at[df['日期']=='2019-05-02', week_column]= 1\n",
    "\n",
    "df.at[df['日期']=='2019-06-06', week_column]= 5\n",
    "df.at[df['日期']=='2019-06-07', week_column]= 7\n",
    "# df.at[df['日期']=='2019-06-08', week_column]= 7\n",
    "\n",
    "df.at[df['日期'] == '2019-09-12', week_column] = 5\n",
    "df.at[df['日期'] == '2019-09-13', week_column] = 7  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入大氣資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atmosphericFactor = pd.read_csv('Data/FromCODIS_clean_daily_ByRegion(ElectRatio)_20160101_20191031.csv')\n",
    "\n",
    "#位移溫度\n",
    "atmosphericFactor['Temp_Taipei_shift'] = atmosphericFactor['Temp_Taipei'].shift(-7)\n",
    "atmosphericFactor['Temp_Taichung_shift'] = atmosphericFactor['Temp_Taichung'].shift(-7)\n",
    "atmosphericFactor['Temp_Kao_shift'] = atmosphericFactor['Temp_Kao'].shift(-7)\n",
    "\n",
    "atmosphericFactor['Temp_avg_shift'] = atmosphericFactor['Temp_avg'].shift(-7)\n",
    "\n",
    "#位移雨量\n",
    "atmosphericFactor['Precp_Taipei_shift'] = atmosphericFactor['Precp_Taipei'].shift(-7)\n",
    "atmosphericFactor['Precp_Taichung_shift'] = atmosphericFactor['Precp_Taichung'].shift(-7)\n",
    "atmosphericFactor['Precp_Kao_shift'] = atmosphericFactor['Precp_Kao'].shift(-7)\n",
    "\n",
    "atmosphericFactor['Precp_ratio_shift'] = (atmosphericFactor['Precp_Taipei']*atmosphericFactor['ElectRatio_north'] + atmosphericFactor['Precp_Taichung']*atmosphericFactor['ElectRatio_central'] + atmosphericFactor['Precp_Kao']*atmosphericFactor['ElectRatio_south']).shift(-7)\n",
    "atmosphericFactor['Precp_avg_shift'] = (atmosphericFactor['Precp_Taipei_shift'] + atmosphericFactor['Precp_Taichung_shift'] + atmosphericFactor['Precp_Kao_shift'])/3 \n",
    "\n",
    "\n",
    "#位移氣壓\n",
    "atmosphericFactor['StnPres_Taipei_shift'] = atmosphericFactor['StnPres_Taipei'].shift(-7)\n",
    "atmosphericFactor['StnPres_Taichung_shift'] = atmosphericFactor['StnPres_Taichung'].shift(-7)\n",
    "atmosphericFactor['StnPres_Kao_shift'] = atmosphericFactor['StnPres_Kao'].shift(-7)\n",
    "\n",
    "#位移濕度\n",
    "atmosphericFactor['RH_Taipei_shift'] = atmosphericFactor['RH_Taipei'].shift(-7)\n",
    "atmosphericFactor['RH_Taichung_shift'] = atmosphericFactor['RH_Taichung'].shift(-7)\n",
    "atmosphericFactor['RH_Kao_shift'] = atmosphericFactor['RH_Kao'].shift(-7)\n",
    "\n",
    "#位移風速\n",
    "atmosphericFactor['WS_Taipei_shift'] = atmosphericFactor['WS_Taipei'].shift(-7)\n",
    "atmosphericFactor['WS_Taichung_shift'] = atmosphericFactor['WS_Taichung'].shift(-7)\n",
    "atmosphericFactor['WS_Kao_shift'] = atmosphericFactor['WS_Kao'].shift(-7)\n",
    "\n",
    "atmosphericFactor = atmosphericFactor[(atmosphericFactor['Date']>='2016-01-01') & (atmosphericFactor['Date']<='2019-09-30')]\n",
    "\n",
    "df = pd.concat([df, atmosphericFactor.iloc[:,1:]], axis=1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atmosphericFactor[['Date', \n",
    "                   'Precp_Taipei', 'ElectRatio_north',\n",
    "                   'Precp_Taichung', 'ElectRatio_central',\n",
    "                   'Precp_Kao', 'ElectRatio_south', \n",
    "                   'Precp_Taipei_shift', 'Precp_ratio_shift']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PrecpTaipeiShift_interval'] = np.nan\n",
    "df['PrecpTaipeiShift_interval'] = df['PrecpTaipeiShift_interval'].fillna(0)\n",
    "\n",
    "df.loc[df['Precp_Taipei_shift']>=80, 'PrecpTaipeiShift_interval'] = 1\n",
    "df.loc[df['Precp_Taipei_shift']>=200, 'PrecpTaipeiShift_interval'] = 2\n",
    "df.loc[df['Precp_Taipei_shift']>=350, 'PrecpTaipeiShift_interval'] = 3\n",
    "df.loc[df['Precp_Taipei_shift']>=500, 'PrecpTaipeiShift_interval'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['日期']>='2017-01-01') & (df['日期']<='2019-09-30')].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 處理 ＆ 位移 其他欄位\n",
    "要預測未來7天的值，故將其他欄位左移7天，並手動補足剩餘欄位的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfDays_2016 = len(pd.date_range(start='2016-01-01', end='2016-12-31'))\n",
    "numberOfDays_2017 = len(pd.date_range(start='2017-01-01', end='2017-12-31'))\n",
    "numberOfDays_2018 = len(pd.date_range(start='2018-01-01', end='2018-12-31'))\n",
    "numberOfDays_2019 = len(pd.date_range(start='2019-01-01', end='2019-09-30'))\n",
    "\n",
    "numberOfDays = np.concatenate((np.arange(1, numberOfDays_2016+1), np.arange(1, numberOfDays_2017+1), np.arange(1,numberOfDays_2018 +1), np.arange(1,numberOfDays_2019 +1)),axis=0)\n",
    "df['dayOfYear'] = numberOfDays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isHoliday_shift'] = df['isHoliday'].shift(-7)\n",
    "df.loc[1362:1365, (\"isHoliday_shift\")] = 0\n",
    "df.loc[1366:1367, (\"isHoliday_shift\")] = 1\n",
    "df.loc[1368, (\"isHoliday_shift\")] = 0\n",
    "# df[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['尖峰負載(MW)_ori'] = df['尖峰負載(MW)']\n",
    "df['尖峰負載(MW)'] = df['尖峰負載(MW)'].shift(-7)\n",
    "\n",
    "#往前位移七天\n",
    "preDateEnd_ = datetime.datetime.strptime(preDateEnd, \"%Y-%m-%d\")\n",
    "preDateEnd_7ago = datetime.datetime(preDateEnd_.year, preDateEnd_.month, preDateEnd_.day) + datetime.timedelta(days=-7)\n",
    "preDateEnd_7ago = preDateEnd_7ago.strftime(\"%Y-%m-%d\")\n",
    "preDateEnd_7ago\n",
    "\n",
    "df.at[(df['日期']>=preDateStart) & (df['日期']<=preDateEnd), '尖峰負載(MW)']= geek.nan\n",
    "df.at[(df['日期']>=preDateStart) & (df['日期']<=preDateEnd_7ago), '尖峰負載(MW)']= (predictPeakLoad['尖峰負載(MW)_predict'][7:].tolist())\n",
    "\n",
    "for idx, val in enumerate(df['尖峰負載(MW)']):\n",
    "    if(pd.isnull(val)):\n",
    "        newValue = (df.loc[idx-7]['尖峰負載(MW)_ori'] + df.loc[idx-14]['尖峰負載(MW)_ori'])/2\n",
    "        df.loc[idx, '尖峰負載(MW)'] = newValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekUpdate_shift'] = df['week_update'].shift(-7)\n",
    "\n",
    "df.loc[1362, (\"weekUpdate_shift\")] = 2\n",
    "df.loc[1363, (\"weekUpdate_shift\")] = 3\n",
    "df.loc[1364, (\"weekUpdate_shift\")] = 4\n",
    "df.loc[1365, (\"weekUpdate_shift\")] = 5\n",
    "df.loc[1366, (\"weekUpdate_shift\")] = 6\n",
    "df.loc[1367, (\"weekUpdate_shift\")] = 7\n",
    "df.loc[1368, (\"weekUpdate_shift\")] = 1\n",
    "# df[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將資料集切割為 train set 與 test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, split_num):\n",
    "    split_num_start = df[df['日期']== trainDateStart].index.item()\n",
    "    split_num = df[df['日期']== preDateStart].index.item()\n",
    "    split_num_end = df[df['日期']== preDateEnd].index.item()\n",
    "    train, test = data[split_num_start:split_num], data[split_num:split_num_end+1]\n",
    "    # restructure into windows of weekly data\n",
    "    train = np.array(np.split(train, len(train) / 7))\n",
    "    test = np.array(np.split(test, len(test) / 7))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
