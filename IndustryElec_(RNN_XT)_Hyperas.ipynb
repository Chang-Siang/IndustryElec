{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def RMSE(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def calcError(origin, forecast):\n",
    "    print(\"RMSE\", RMSE(origin, forecast))\n",
    "    print(\"MAPE\", MAPE(origin, forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def showPlot(true, prediction, model , test_set, size='M', save=False):\n",
    "    if(size=='L'):\n",
    "        plt.figure(figsize=(28, 10))\n",
    "    plt.plot(true, color = 'red', label = 'Real')\n",
    "    plt.plot(prediction, color = 'blue', label = 'Prediction')\n",
    "    plt.title('Industry Elec Prediction' + model + ' ' + test_set + ' t' + str(t))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('kW')\n",
    "    plt.legend()\n",
    "    if(save):\n",
    "        plt.savefig('Image/' + model + '-' + test_set + '-' + str(t) + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augFeatures(data, features_select):\n",
    "    data = pd.DataFrame(data[features_select])\n",
    "    data.shape\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def normalize(data):\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))\n",
    "    data_scaled = pd.DataFrame(sc.fit_transform(data))\n",
    "    return sc, data_scaled \n",
    "\n",
    "def deNormalize(sc, value):\n",
    "    value_unscaled = value * (sc.data_max_[0]-sc.data_min_[0]) + sc.data_min_[0]\n",
    "    return value_unscaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, pastDay=7, futureDay=7):\n",
    "    split_num_start = df[df['Date'] == trainFrom].index.item()\n",
    "    split_num = df[df['Date'] == testFrom].index.item()\n",
    "    split_num_end = df[df['Date'] == testTo].index.item()\n",
    "    RawTrain = data[split_num_start:split_num]\n",
    "    SelfTest = data[split_num_start:split_num - futureDay]\n",
    "    SelfTruth = data[split_num_start + pastDay:split_num][0]\n",
    "    RawTest = data[split_num - pastDay:split_num_end + 1 - futureDay]\n",
    "    RawTrurh = data[split_num:split_num_end + 1][0]\n",
    "    print(\"RawTrain\", RawTrain.shape)\n",
    "    print(\"RawTest, RawTrurh\", RawTest.shape, RawTrurh.shape)\n",
    "    print(\"SelfTest, SelfTruth\", SelfTest.shape, SelfTruth.shape)\n",
    "    return RawTrain, RawTest, RawTrurh, SelfTest, SelfTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastDay=7, futureDay=7):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(pastDay, len(train)-futureDay):\n",
    "        X_train.append(train[i-pastDay:i])\n",
    "        Y_train.append(train[i:i+futureDay, 0])\n",
    "    X_train, Y_train = np.array(X_train), np.array(Y_train)  \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTest(test, pastDay=7, futureDay=7):\n",
    "    X_test = []\n",
    "    for i in range(0, int(len(test)/futureDay)-(pastDay-futureDay)):\n",
    "        X_test.append(test[futureDay*i:futureDay*i+pastDay])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))  \n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, input_data, shape):\n",
    "    forecast_temp = model.predict(input_data)\n",
    "    forecast = []\n",
    "    for i in range(forecast_temp.shape[0]):\n",
    "        forecast= np.concatenate((forecast, forecast_temp[i]), axis=0)\n",
    "    forecast = np.reshape(forecast, (shape[0], shape[1]))\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, Flatten, RepeatVector\n",
    "from keras.layers import SimpleRNN, LSTM, CuDNNLSTM\n",
    "from keras.layers import Dropout, BatchNormalization, Bidirectional\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X, Y, Xv, Yv):\n",
    "    epochs = 1000\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units = {{choice([50,100,150,200,250,300])}}, activation='relu', input_shape = (X.shape[1], X.shape[2])))\n",
    "    model.add(RepeatVector(7))\n",
    "    model.add(SimpleRNN({{choice([50,100,150,200,250,300])}}, activation='relu', return_sequences=True))\n",
    "    if {{choice([\"True\",\"False\"])}} == \"True\":\n",
    "        model.add(Dropout({{uniform(0, 0.3)}}))\n",
    "    model.add(TimeDistributed(Dense({{choice([50,100,150,200,250,300])}}, activation='relu')))\n",
    "    if {{choice([\"True\",\"False\"])}} == \"True\":\n",
    "        model.add(Dropout({{uniform(0, 0.3)}}))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 7))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=15, mode='min', verbose=0)\n",
    "    earlyStop=EarlyStopping(monitor=\"val_loss\", patience=20, mode=\"min\", restore_best_weights=True)\n",
    "    model.fit(X, Y, \n",
    "              epochs=epochs, batch_size={{choice([16, 32, 50, 100])}}, \n",
    "              verbose=0, \n",
    "              validation_data=(Xv, Yv), \n",
    "              callbacks=[reduce_lr, earlyStop])\n",
    "    return {'loss': min(model.history.history['val_loss']), 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    def augFeatures(data, features_select):\n",
    "        data = pd.DataFrame(data[features_select])\n",
    "        data.shape\n",
    "        return data\n",
    "    def normalize(data):\n",
    "        sc = MinMaxScaler(feature_range = (0, 1))\n",
    "        data_scaled = pd.DataFrame(sc.fit_transform(data))\n",
    "        return sc, data_scaled \n",
    "    def deNormalize(sc, value):\n",
    "        value_unscaled = value * (sc.data_max_[0]-sc.data_min_[0]) + sc.data_min_[0]\n",
    "        return value_unscaled \n",
    "    def split_dataset(data, pastDay=7, futureDay=7):\n",
    "        split_num_start = df[df['Date'] == trainFrom].index.item()\n",
    "        split_num = df[df['Date'] == testFrom].index.item()\n",
    "        split_num_end = df[df['Date'] == testTo].index.item()\n",
    "        RawTrain = data[split_num_start:split_num]\n",
    "        SelfTest = data[split_num_start:split_num - futureDay]\n",
    "        SelfTruth = data[split_num_start + pastDay:split_num][0]\n",
    "        RawTest = data[split_num - pastDay:split_num_end + 1 - futureDay]\n",
    "        RawTrurh = data[split_num:split_num_end + 1][0]\n",
    "        print(\"RawTrain\", RawTrain.shape)\n",
    "        print(\"RawTest, RawTrurh\", RawTest.shape, RawTrurh.shape)\n",
    "        print(\"SelfTest, SelfTruth\", SelfTest.shape, SelfTruth.shape)\n",
    "        return RawTrain, RawTest, RawTrurh, SelfTest, SelfTruth\n",
    "    def splitData(X, Y, rate):\n",
    "        X_train = X[int(X.shape[0]*rate):]\n",
    "        Y_train = Y[int(Y.shape[0]*rate):]\n",
    "        X_val = X[:int(X.shape[0]*rate)]\n",
    "        Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "        return X_train, Y_train, X_val, Y_val\n",
    "    def buildTrain(train, pastDay=7, futureDay=7):\n",
    "        X_train, Y_train = [], []\n",
    "        for i in range(pastDay, len(train)-futureDay):\n",
    "            X_train.append(train[i-pastDay:i])\n",
    "            Y_train.append(train[i:i+futureDay, 0])\n",
    "        X_train, Y_train = np.array(X_train), np.array(Y_train)  \n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "        return X_train, Y_train\n",
    "    features = [\n",
    "            'kW', \n",
    "            'PeakLoad(MW)_shift7', \n",
    "            'isHoliday_shift7', \n",
    "            'dayOfYear', \n",
    "            'weekUpdate_shift7', \n",
    "            'Temp_Taipei_shift7'\n",
    "           ]\n",
    "    trainFrom = '2017-01-04'\n",
    "    trainTo = '2019-01-01'\n",
    "    testFrom = '2019-01-02'\n",
    "    testTo = '2019-09-24'\n",
    "    df = pd.read_csv('Data/industryElec_processed_20160101_20190930.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "    RawData = augFeatures(df, features)\n",
    "    sc, RawData = normalize(RawData)\n",
    "    Timesteps = 7\n",
    "    OutputDay = 7\n",
    "    RawTrain, RawTest, RawTrurh, SelfTest, SelfTruth  = split_dataset(RawData, Timesteps, OutputDay)\n",
    "    X_train, Y_train = buildTrain(RawTrain.values, Timesteps, OutputDay)\n",
    "    X, Y, Xv, Yv= splitData(X_train, Y_train, 0.1)\n",
    "    return X, Y, Xv, Yv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawTrain (728, 6)\n",
      "RawTest, RawTrurh (266, 6) (266,)\n",
      "SelfTest, SelfTruth (721, 6) (721,)\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'cp950' codec can't decode byte 0xe2 in position 19414: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-dc279928574e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                       \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                                       notebook_name='IndustryElec_(RNN_XT)_Hyperas')\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evalutation of best performing model:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[0;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mmodel_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_model_string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mmodel_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hyperopt_model_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[0mtemp_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./temp_model.py'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mwrite_temp_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mget_hyperopt_model_string\u001b[1;34m(model, data, functions, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mnotebook_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/{}.ipynb\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotebook_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m             \u001b[0mnotebook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNO_CONVERT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[0mexporter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPythonExporter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexporter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_notebook_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'cp950' codec can't decode byte 0xe2 in position 19414: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "tStart = time.time()\n",
    "\n",
    "X, Y, Xv, Yv = data()\n",
    "\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=30,\n",
    "                                      trials=Trials(),\n",
    "                                      verbose=True,\n",
    "                                      notebook_name='IndustryElec_(RNN_XT)_Hyperas')\n",
    "\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(Xv, Yv))\n",
    "print(best_run)\n",
    "\n",
    "tEnd = time.time()\n",
    "print('Total time spent.....',tEnd - tStart, 'second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('Best_Model_RNN_Aux_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "            'kW', \n",
    "            'PeakLoad(MW)_shift7', \n",
    "            'isHoliday_shift7', \n",
    "            'dayOfYear', \n",
    "            'weekUpdate_shift7', \n",
    "            'Temp_Taipei_shift7'\n",
    "           ]\n",
    "trainFrom = '2017-01-04'\n",
    "trainTo = '2019-01-01'\n",
    "testFrom = '2019-01-02'\n",
    "testTo = '2019-09-24'\n",
    "df = pd.read_csv('Data/industryElec_processed_20160101_20190930.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "\n",
    "RawData = augFeatures(df, features)\n",
    "sc, RawData = normalize(RawData)\n",
    "\n",
    "Timesteps = 7\n",
    "OutputDay = 7\n",
    "\n",
    "RawTrain, RawTest, RawTrurh, SelfTest, SelfTruth  = split_dataset(RawData, Timesteps, OutputDay)\n",
    "\n",
    "X_train, Y_train = buildTrain(RawTrain.values, Timesteps, OutputDay)\n",
    "S_test = buildTest(SelfTest.values, Timesteps, OutputDay)\n",
    "X_test = buildTest(RawTest.values, Timesteps, OutputDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 3\n",
    "save = True\n",
    "model_name = '(XT_RNN_2017_Hyperas_Aux)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_trurh = pd.DataFrame(SelfTruth)\n",
    "self_trurh = deNormalize(sc, self_trurh.values)\n",
    "self_predict = forecast(best_model, S_test, self_trurh.shape)\n",
    "self_predict = deNormalize(sc, self_predict)\n",
    "calcError(self_trurh, self_predict)\n",
    "showPlot(self_trurh, self_predict, model_name , \"self\", size=\"L\", save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trurh = pd.DataFrame(RawTrurh)\n",
    "test_trurh = deNormalize(sc, test_trurh.values)\n",
    "test_predict = forecast(best_model, X_test, test_trurh.shape)\n",
    "test_predict = deNormalize(sc, test_predict)\n",
    "calcError(test_trurh, test_predict)\n",
    "showPlot(test_trurh, test_predict, model_name , str(266), save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
