{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/autonomio/hyperio/master/logo.png' width=250px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Quick start\n",
    "    conda install tensorflow=1.14\n",
    "    (conda install tensorflow-gpu=1.14)\n",
    "    \n",
    "    pip install talos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Overview\n",
    "請將您的程式碼遵照下列步驟修改，以套用Talos超參數選擇器:\n",
    "1. 引用 talos 套件\n",
    "2. 替你的 Keras model 加入 'params' 標籤\n",
    "3. 定義 \"超參數組合\"\n",
    "4. 執行超參數搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 更多細節 https://autonomio.github.io/talos/#/README?id=quick-start\n",
    "- 官方範本 https://tinyurl.com/r7gebyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load packege\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load packege\n",
    "from plotly.offline import iplot\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, Flatten, RepeatVector, Activation\n",
    "from keras.layers import SimpleRNN, LSTM, CuDNNLSTM\n",
    "from keras.layers import Dropout, BatchNormalization, Bidirectional\n",
    "from keras import optimizers, regularizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 分配顯存空間，未使用 tensorflow-GPU 可以跳過這段\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.45\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sub：Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     4,
     7
    ]
   },
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def RMSE(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def calcError(origin, forecast):\n",
    "    print(\"RMSE\", RMSE(origin, forecast))\n",
    "    print(\"MAPE\", MAPE(origin, forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 列印績效圖表，可以選擇是否儲存\n",
    "def showPlot(true, prediction, title, sub_title, size='M', save=False):\n",
    "    size == 'L' and plt.figure(figsize=(28, 10))\n",
    "    plt.plot(true, color='red', label='Real')\n",
    "    plt.plot(prediction, color='blue', label='Prediction')\n",
    "    plt.title('Industry Elec Prediction %s %s t:%d' % (title, sub_title, time))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('kW')\n",
    "    plt.legend()\n",
    "    save and plt.savefig('Image/%s-%s-%d.png' % (title, sub_title, time))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sub：Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# 資料維度擷取\n",
    "def augFeatures(data, features_select):\n",
    "    data = pd.DataFrame(data[features_select])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     2,
     6
    ]
   },
   "outputs": [],
   "source": [
    "# 資料正規化與尺度還原\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def normalize(data):\n",
    "    sc = MinMaxScaler(feature_range=(0, 1))\n",
    "    data_scaled = pd.DataFrame(sc.fit_transform(data))\n",
    "    return sc, data_scaled\n",
    "def deNormalize(sc, value):\n",
    "    value_unscaled = value * \\\n",
    "        (sc.data_max_[0]-sc.data_min_[0]) + sc.data_min_[0]\n",
    "    value_unscaled = value_unscaled.reshape(value_unscaled.shape[0])\n",
    "    return value_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 根據給定的時間範圍自動產生訓練集\n",
    "def split_train(data, trainFrom, trainTo, pastDay=7, futureDay=7):\n",
    "    num_train_from = df[df['Date'] == trainFrom].index.item()\n",
    "    num_train_to = df[df['Date'] == trainTo].index.item() + 1\n",
    "    RawTrain = data[num_train_from:num_train_to]\n",
    "    print('RawTrain', RawTrain.shape)\n",
    "    return RawTrain\n",
    "# 根據給定的時間範圍自動產生測試集\n",
    "def split_test(data, testFrom, testTo, pastDay=7, futureDay=7):\n",
    "    num_test_from = df[df['Date'] == testFrom].index.item()\n",
    "    num_test_to = df[df['Date'] == testTo].index.item() + 1\n",
    "    RawTest = data[num_test_from-pastDay:num_test_to]\n",
    "    print('RawTest', RawTest.shape)\n",
    "    return RawTest\n",
    "# 拆分訓練與驗證，需要手動切割時才使用\n",
    "def split_val(X, Y, rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 滾動訓練資料\n",
    "def buildTrain(train, pastDay, futureDay):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(pastDay, len(train)-futureDay):\n",
    "        X_train.append(train[i-pastDay:i])\n",
    "        Y_train.append(train[i:i+futureDay, 0])  # kW\n",
    "    X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
    "    print('X_train.shape, Y_train.shape', X_train.shape, Y_train.shape)\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 滾動測試資料\n",
    "def buildTest(test, pastDay, futureDay):\n",
    "    input_set, truth_set = test, test[pastDay:]\n",
    "    X_test, Y_truth = [], []\n",
    "    for i in range(0, int((test.shape[0]-pastDay)/futureDay)):\n",
    "        X_test.append(input_set[futureDay*i:futureDay*i+pastDay])\n",
    "        Y_truth.append(truth_set[i*futureDay:(i+1)*futureDay, 0])  # kW\n",
    "    testInput, testTruth = np.array(X_test), np.array(Y_truth)\n",
    "    testInput = testInput.reshape(testInput.shape[0], testInput.shape[1], testInput.shape[2])\n",
    "    testTruth = testTruth.reshape(testTruth.shape[0] * testTruth.shape[1])\n",
    "    print('testInput.shape, testTruth.shape', testInput.shape, testTruth.shape)\n",
    "    return testInput, testTruth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sub：Model\n",
    "Configuring the Keras Model for Talos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Talos] 1.引用 talos 套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import the talos libraries and packages\n",
    "import sys\n",
    "import talos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Talos] 2.替你的 Keras model 加入 'params' 標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we have to make sure to input data and params into the function\n",
    "def create_model(x_train, y_train, x_val, y_val, params):\n",
    "#     L2 = regularizers.l2(0.01)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(CuDNNLSTM(units=200, input_shape=(\n",
    "        x_train.shape[1], x_train.shape[2])))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(RepeatVector(futureDay))  # futureDay=7\n",
    "\n",
    "    model.add(CuDNNLSTM(200, return_sequences=True))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    model.add(TimeDistributed(\n",
    "        Dense(200, activation='relu', kernel_regularizer=L2)))\n",
    "#     model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    reduceLR = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=params['reduceLR_rate'],\n",
    "        patience=params['reduceLR_t'], mode='min', verbose=0)\n",
    "    earlyStop = EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=['earlyStop_t'], mode=\"min\",\n",
    "        restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=[x_val, y_val],\n",
    "                        epochs=1000, batch_size=params['batch_size'],\n",
    "                        verbose=0,\n",
    "                        callbacks=[reduceLR, earlyStop])\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Talos] 3.定義 \"超參數組合\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'reduceLR_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "     'reduceLR_t': [30, 50],\n",
    "     'earlyStop_t': [150, 300]\n",
    "#      'dropout': [0.0, 0.1, 0.01],\n",
    "#      'layer_1_node': [100, 200, 400],\n",
    "#      'layer_2_node': [50, 200],\n",
    "#      'layer_3_node': [50, 200],\n",
    "     'batch_size': [16, 32, 64]\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, input_data):\n",
    "    forecast_temp = model.predict(input_data)\n",
    "    forecast = forecast_temp.reshape(\n",
    "        forecast_temp.shape[0] * forecast_temp.shape[1])\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, sc, truth, input_set):\n",
    "    truth = pd.DataFrame(truth)\n",
    "    truth = deNormalize(sc, truth.values)\n",
    "    predict = model_forecast(model, input_set)\n",
    "    predict = deNormalize(sc, predict)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1369, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/RawData_THU-WED.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'kW',\n",
    "    'PeakLoad(MW)_shift7',\n",
    "    'isHoliday_shift7',\n",
    "    'dayOfYear',\n",
    "    'weekUpdate_shift7',\n",
    "    'Temp_Taipei_shift7'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測時間\n",
    "trainFrom, trainTo = '2017-01-04', '2019-01-01' # 3~2\n",
    "trainFrom, trainTo = '2017-01-05', '2018-12-26' # 4~3\n",
    "\n",
    "testFrom, testTo = '2019-01-02', '2019-09-24' # 3~2\n",
    "testFrom, testTo = '2019-01-03', '2019-09-25' # 4~3\n",
    "testFrom, testTo = '2019-01-06', '2019-09-28' # 6~5\n",
    "\n",
    "# 步數選擇\n",
    "pastDay = 7\n",
    "futureDay = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawTrain (721, 6)\n",
      "RawTest (721, 6)\n",
      "RawTest (273, 6)\n",
      "X_train.shape, Y_train.shape (707, 7, 6) (707, 7)\n",
      "testInput.shape, testTruth.shape (102, 7, 6) (714,)\n",
      "testInput.shape, testTruth.shape (38, 7, 6) (266,)\n"
     ]
    }
   ],
   "source": [
    "# 特徵選取\n",
    "RawData = augFeatures(df, features)\n",
    "\n",
    "# 正規化\n",
    "sc, RawData = normalize(RawData)\n",
    "\n",
    "# 資料範圍選取\n",
    "RawTrain = split_train(RawData, trainFrom, trainTo, pastDay, futureDay)\n",
    "RawSelf = split_test(RawData, '2017-01-12', '2018-12-26', pastDay, futureDay)\n",
    "RawTest = split_test(RawData, testFrom, testTo, pastDay, futureDay)\n",
    "\n",
    "# 資料打包\n",
    "X_train, Y_train = buildTrain(RawTrain.values, pastDay, futureDay)\n",
    "selfInput, selfTruth = buildTest(RawSelf.values, pastDay, futureDay)\n",
    "testInput, testTruth = buildTest(RawTest.values, pastDay, futureDay)\n",
    "\n",
    "# 驗證資料\n",
    "# X, Y, Xv, Yv= split_val(X_train, Y_train, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Talos] 4.執行超參數搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\siang\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████▎                                                            | 157/1080 [15:25:50<113:19:20, 441.99s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# run the experiment\n",
    "# fraction_limit = 要從所有的可能性中隨機挑選多少比例的組合進行實驗\n",
    "Y_train = Y_train.reshape((Y_train.shape[0], Y_train.shape[1], 1))\n",
    "scan_object = talos.Scan(x=X_train, y=Y_train, val_split=0.1,\n",
    "                         model=create_model,\n",
    "                         params=p,\n",
    "                         reduction_metric='val_loss', minimize_loss=True,\n",
    "                         fraction_limit=0.5, \n",
    "                         experiment_name='breast_cancer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Talos] 檢視實驗結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scan_object_top10 = scan_object.data.sort_values([\"val_loss\"],ascending=True).head(10)\n",
    "# 打印檢視\n",
    "scan_object_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出結果\n",
    "dfOut = pd.DataFrame(scan_object_top10)\n",
    "dfOut.to_csv('talos_hypers_temp2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Talos] 分析實驗結果\n",
    "以下示範檢視模型對參數組合的反應幅度及參數重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Scan object as input\n",
    "analyze_object = talos.Analyze(scan_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# line plot\n",
    "# analyze_object.plot_line('val_mae')\n",
    "analyze_object.plot_line('val_loss')\n",
    "\n",
    "# up to two dimensional kernel density estimator\n",
    "# analyze_object.plot_kde('val_loss')\n",
    "\n",
    "# heatmap correlation\n",
    "analyze_object.plot_corr('val_loss', ['val_mae'])\n",
    "\n",
    "# a four dimensional bar grid\n",
    "# analyze_object.plot_bars('batch_size', 'val_mae', 'layer_1_node', 'lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Talos] 使用最佳模型預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 0\n",
    "save = False\n",
    "model_name = '(Talos_Best_Model_RNN)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 獲取最佳模型，必須提供判斷模型優劣的指標\n",
    "best_model =  scan_object.best_model(metric='val_loss', asc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "total_self = []\n",
    "total_test = []\n",
    "\n",
    "# 為求公平衡量模型，執行 n次\n",
    "for i in range(1):\n",
    "    print(\"round: \", str(i))\n",
    "    self_predict = model_evaluate(best_model, sc, selfTruth, selfInput)\n",
    "    test_predict = model_evaluate(best_model, sc, testTruth, testInput)\n",
    "    total_self.append(self_predict.reshape(self_predict.shape[0]))\n",
    "    total_test.append(test_predict.reshape(test_predict.shape[0]))\n",
    "\n",
    "# 平均處理 n個模型的預測結果\n",
    "mean_self = np.array(total_self).mean(axis=0)\n",
    "mean_test = np.array(total_test).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自我測試\n",
    "self_trurh = pd.DataFrame(selfTruth)\n",
    "self_trurh = deNormalize(sc, self_trurh.values)\n",
    "calcError(self_trurh, mean_self)\n",
    "showPlot(self_trurh, mean_self, model_name, \"self\", size=\"L\", save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實際測試\n",
    "test_trurh = pd.DataFrame(testTruth)\n",
    "test_trurh = deNormalize(sc, test_trurh.values)\n",
    "calcError(test_trurh, mean_test)\n",
    "showPlot(test_trurh, mean_test, model_name, str(len(testTruth)), save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "best_model.save('Model/Talos/talos_model_%d.h5'%(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
