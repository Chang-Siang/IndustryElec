{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sub：Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def RMSE(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def calcError(origin, forecast):\n",
    "    print(\"RMSE\", RMSE(origin, forecast))\n",
    "    print(\"MAPE\", MAPE(origin, forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def showPlot(true, prediction, model , test_set, size='M', save=False):\n",
    "    if(size=='L'):\n",
    "        plt.figure(figsize=(28, 10))\n",
    "    plt.plot(true, color = 'red', label = 'Real')\n",
    "    plt.plot(prediction, color = 'blue', label = 'Prediction')\n",
    "    plt.title('Industry Elec Prediction' + model + ' ' + test_set + ' t' + str(t))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('kW')\n",
    "    plt.legend()\n",
    "    if(save):\n",
    "        plt.savefig('Image/' + model + '-' + test_set + '-' + str(t) + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sub：Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1369, 12)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20160101~20161231 [0~366]\n",
    "# 20170101~20171231 [366~731]\n",
    "# 20180101~20181231 [731~1095]\n",
    "# 20190101~20190930 [1096~1368]\n",
    "# df = pd.read_csv('Data/elec_merge_20160101_20190930.csv')\n",
    "df = pd.read_csv('Data/industryElec_processed_20160101_20190930.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>kW</th>\n",
       "      <th>PeakLoad(MW)</th>\n",
       "      <th>isHoliday</th>\n",
       "      <th>week</th>\n",
       "      <th>week_update</th>\n",
       "      <th>dayOfYear</th>\n",
       "      <th>Temp_Taipei</th>\n",
       "      <th>PeakLoad(MW)_shift7</th>\n",
       "      <th>isHoliday_shift7</th>\n",
       "      <th>weekUpdate_shift7</th>\n",
       "      <th>Temp_Taipei_shift7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>263.799</td>\n",
       "      <td>23038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14.6</td>\n",
       "      <td>26400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>261.975</td>\n",
       "      <td>23209</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>24308.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>266.167</td>\n",
       "      <td>23686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>302.227</td>\n",
       "      <td>27518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>27207.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>313.328</td>\n",
       "      <td>27635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>17.8</td>\n",
       "      <td>26747.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       kW  PeakLoad(MW)  isHoliday  week  week_update  dayOfYear  \\\n",
       "0 2016-01-01  263.799         23038        1.0     5            7          1   \n",
       "1 2016-01-02  261.975         23209        1.0     6            6          2   \n",
       "2 2016-01-03  266.167         23686        1.0     7            7          3   \n",
       "3 2016-01-04  302.227         27518        0.0     1            1          4   \n",
       "4 2016-01-05  313.328         27635        0.0     2            2          5   \n",
       "\n",
       "   Temp_Taipei  PeakLoad(MW)_shift7  isHoliday_shift7  weekUpdate_shift7  \\\n",
       "0         14.6              26400.0               0.0                5.0   \n",
       "1         15.7              24308.0               1.0                6.0   \n",
       "2         16.0              23490.0               1.0                7.0   \n",
       "3         17.7              27207.0               0.0                1.0   \n",
       "4         17.8              26747.0               0.0                2.0   \n",
       "\n",
       "   Temp_Taipei_shift7  \n",
       "0                12.0  \n",
       "1                12.1  \n",
       "2                16.2  \n",
       "3                13.5  \n",
       "4                11.4  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料維度擷取\n",
    "def augFeatures(data, features_select):\n",
    "    data = pd.DataFrame(data[features_select])\n",
    "    data.shape\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def normalize(data):\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))\n",
    "    data_scaled = pd.DataFrame(sc.fit_transform(data))\n",
    "    return sc, data_scaled \n",
    "\n",
    "def deNormalize(sc, value):\n",
    "    value_unscaled = value * (sc.data_max_[0]-sc.data_min_[0]) + sc.data_min_[0]\n",
    "    return value_unscaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 僅負責滾動資料\n",
    "def buildTrain(train, pastDay=7, futureDay=7):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(pastDay, len(train)-futureDay):\n",
    "        X_train.append(train[i-pastDay:i])\n",
    "        Y_train.append(train[i:i+futureDay, 0])\n",
    "    X_train, Y_train = np.array(X_train), np.array(Y_train)  \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    print('X_train.shape, Y_train.shape', X_train.shape, Y_train.shape)\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分訓練與驗證，需要手動切割時才使用\n",
    "def splitData(X, Y, rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, input_data, shape):\n",
    "    forecast_temp = model.predict(input_data)\n",
    "    # Append Data\n",
    "    forecast = []\n",
    "    for i in range(forecast_temp.shape[0]):\n",
    "        forecast= np.concatenate((forecast, forecast_temp[i]), axis=0)\n",
    "    # Reshape\n",
    "    forecast = np.reshape(forecast, (shape[0], shape[1]))\n",
    "    print('Truth.shape, Forecast.shape', shape, forecast.shape)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sub：Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 關閉警告\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "# Import the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, Flatten, RepeatVector\n",
    "from keras.layers import SimpleRNN, LSTM, CuDNNLSTM\n",
    "from keras.layers import Dropout, BatchNormalization, Bidirectional\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(shape, train_x, train_y):\n",
    "    epochs, batch_size = 1000, 50\n",
    "    # batch_size = 16\n",
    "    # epochs = 200\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units = 200, activation='relu', input_shape = (shape[1], shape[2])))\n",
    "    model.add(RepeatVector(7))\n",
    "    model.add(SimpleRNN(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    #     model.add(Dropout(dropout_rate))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, mode='min', verbose=0)\n",
    "    earlyStop=EarlyStopping(monitor=\"val_loss\", patience=20, mode=\"min\", restore_best_weights=True)\n",
    "    modelResult = model.fit(train_x, train_y, \n",
    "                            epochs=epochs, batch_size=batch_size, \n",
    "                            verbose=0, \n",
    "                            validation_split=0.1, \n",
    "#                             shuffle=False,\n",
    "                            callbacks=[reduce_lr, earlyStop])\n",
    "    return model, modelResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, sc, SelfTruth, S_test, RawTrurh, X_test):\n",
    "    self_trurh = pd.DataFrame(SelfTruth)\n",
    "    self_trurh = deNormalize(sc, self_trurh.values)\n",
    "    self_predict = forecast(model, S_test, self_trurh.shape)\n",
    "    self_predict = deNormalize(sc, self_predict)\n",
    "    test_trurh = pd.DataFrame(RawTrurh)\n",
    "    test_trurh = deNormalize(sc, test_trurh.values)\n",
    "    test_predict = forecast(model, X_test, test_trurh.shape)\n",
    "    test_predict = deNormalize(sc, test_predict)\n",
    "    return self_predict, test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "            'kW', \n",
    "            'PeakLoad(MW)_shift7', \n",
    "            'isHoliday_shift7', \n",
    "            'dayOfYear', \n",
    "            'weekUpdate_shift7', \n",
    "            'Temp_Taipei_shift7',\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFrom = '2017-01-04'\n",
    "trainTo = '2019-01-01'\n",
    "testFrom = '2019-01-02'\n",
    "testTo = '2019-09-24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徵選取\n",
    "RawData = augFeatures(df, features)\n",
    "# 正規化\n",
    "sc, RawData = normalize(RawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 僅負責滾動資料\n",
    "def buildTest(test, shape, pastDay=7, futureDay=7):\n",
    "    X_test = []\n",
    "    buildRange = int(shape[0]/futureDay)\n",
    "    \n",
    "    for i in range(0, buildRange):\n",
    "        X_test.append(test[futureDay*i:futureDay*i+pastDay])\n",
    "    X_test = np.array(X_test)\n",
    "    \n",
    "    print('buildTest.shape', X_test.shape)\n",
    "    \n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))  \n",
    "    print('buildTest.shape', X_test.shape)\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根據給定的時間範圍自動產生訓練、測試資料集\n",
    "def split_dataset(data, pastDay=7, futureDay=7):\n",
    "    num_train_start = df[df['Date'] == trainFrom].index.item()\n",
    "    num_train_end = df[df['Date'] == trainTo].index.item() + 1\n",
    "    num_test_start = df[df['Date'] == testFrom].index.item()\n",
    "    num_test_end = df[df['Date'] == testTo].index.item() + 1\n",
    "    \n",
    "    self_raw_react = (num_train_end-num_train_start-futureDay) % pastDay\n",
    "    self_truth_react = (num_train_end-num_train_start-pastDay) % futureDay\n",
    "    test_raw_react = (num_test_end-num_test_start-futureDay) % pastDay\n",
    "    test_truth_react = (num_test_end-num_test_start) % futureDay\n",
    "\n",
    "    # 訓練資料\n",
    "    RawTrain = data[num_train_start:num_train_end]\n",
    "    # 自我測試集\n",
    "    SelfTest = data[num_train_start:num_train_end]\n",
    "    SelfTruth = data[num_train_start+pastDay:num_train_end-self_truth_react]\n",
    "    # 實際預測集\n",
    "    RawTest = data[num_test_start-pastDay:num_test_end]\n",
    "    RawTruth = data[num_test_start:num_test_end-test_truth_react]\n",
    "\n",
    "    print(\"RawTrain\", RawTrain.shape)\n",
    "    print(\"SelfTest, SelfTruth\", SelfTest.shape, SelfTruth.shape)\n",
    "    print(\"RawTest, RawTrurh\", RawTest.shape, RawTruth.shape)\n",
    "    return RawTrain, RawTest, RawTruth, SelfTest, SelfTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawTrain (728, 6)\n",
      "SelfTest, SelfTruth (728, 6) (721, 6)\n",
      "RawTest, RawTrurh (273, 6) (266, 6)\n",
      "X_train.shape, Y_train.shape (720, 7, 6) (720, 1)\n",
      "buildTest.shape (721, 7, 6)\n",
      "buildTest.shape (721, 7, 6)\n",
      "buildTest.shape (266, 7, 6)\n",
      "buildTest.shape (266, 7, 6)\n"
     ]
    }
   ],
   "source": [
    "# 自定義變數\n",
    "Timesteps = 7\n",
    "OutputDay = 1\n",
    "\n",
    "# 資料選取\n",
    "RawTrain, RawTest, RawTrurh, SelfTest, SelfTruth  = split_dataset(RawData, Timesteps, OutputDay)\n",
    "\n",
    "# 資料打包\n",
    "X_train, Y_train = buildTrain(RawTrain.values, Timesteps, OutputDay)\n",
    "S_test = buildTest(SelfTest.values, SelfTruth.shape, Timesteps, OutputDay)\n",
    "X_test = buildTest(RawTest.values, RawTrurh.shape, Timesteps, OutputDay)\n",
    "\n",
    "# 驗證資料\n",
    "# X, Y, Xv, Yv= splitData(X_train, Y_train, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 721 into shape (721,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-86-4db5b32b6b8e>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model, sc, SelfTruth, S_test, RawTrurh, X_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mself_trurh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSelfTruth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mself_trurh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeNormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself_trurh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mself_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself_trurh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mself_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeNormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtest_trurh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRawTrurh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-83-6c506219476c>\u001b[0m in \u001b[0;36mforecast\u001b[1;34m(model, input_data, shape)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mforecast\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforecast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforecast_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Reshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mforecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforecast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Truth.shape, Forecast.shape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    299\u001b[0m            [5, 6]])\n\u001b[0;32m    300\u001b[0m     \"\"\"\n\u001b[1;32m--> 301\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 721 into shape (721,6)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_self = []\n",
    "total_test = []\n",
    "for i in range(1):\n",
    "    print(i)\n",
    "    model, modelResult = buildModel(X_train.shape, X_train, Y_train)\n",
    "    self_predict, test_predict = evaluate_model(model, sc, SelfTruth, S_test, RawTrurh, X_test)\n",
    "    total_self.append(np.reshape(self_predict, (self_predict.shape[0])))\n",
    "    total_test.append(np.reshape(test_predict, (test_predict.shape[0])))\n",
    "mean_self = np.array(total_self).mean(axis=0)\n",
    "mean_test = np.array(total_test).mean(axis=0)\n",
    "# reshape\n",
    "mean_self = np.reshape(mean_self, (mean_self.shape[0], 1))\n",
    "mean_test = np.reshape(mean_test, (mean_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1\n",
    "save = False\n",
    "# save = False\n",
    "model_name = '(XT_RNN_2017)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load\n",
    "# from keras.models import load_model\n",
    "# model = load_model('Model/industryElec_cLSTM(7to7)_model_0' + str(t) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Self-Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-58772173efec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mself_trurh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSelfTruth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mself_trurh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeNormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself_trurh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcalcError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_trurh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_self\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mshowPlot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_trurh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"self\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_self' is not defined"
     ]
    }
   ],
   "source": [
    "# 自我測試\n",
    "self_trurh = pd.DataFrame(SelfTruth)\n",
    "self_trurh = deNormalize(sc, self_trurh.values)\n",
    "calcError(self_trurh, mean_self)\n",
    "showPlot(self_trurh, mean_self, model_name , \"self\", size=\"L\", save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test-Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實際測試\n",
    "test_trurh = pd.DataFrame(RawTrurh)\n",
    "test_trurh = deNormalize(sc, test_trurh.values)\n",
    "calcError(test_trurh, mean_test)\n",
    "showPlot(test_trurh, mean_test, model_name , str(266), save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# Model.save('Model/industryElec_cLSTM(7to7)_model_01.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
